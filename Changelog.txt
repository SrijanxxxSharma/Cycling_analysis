# This documentation is about the changes done to dataset.

1. I had a data divided in 4 quaters of 2019 year i.e 4 csv files.
2. For organizing and feature engineering I kept few things in mind.
	i)   Data should be easy to digest for a user or analyst.
	ii)  It should answer multiple question not just our question.
	     As data might be used by someone else.
	iii) Clean the data so that it speaks more about itself.

3. Out of four csv file 
   (namely:Divvy_Trips_2019_Q1.csv, Divvy_Trips_2019_Q2.csv, Divvy_Trips_2019_Q3.csv and Divvy_Trips_2019_Q4.csv.
   Divvy_Trips_2019_Q2.csv had different headers so I changed it headers that were same as other files.

4. After checking the format of all headers, files we binded into single file named as 2021_07_18_Formatted_Cycling.csv.

5. Now for proper analysis columns weekday_start, week_num_start, month_start, weekday_end, week_num_end and month_end 
   were added after converting start_time and end_time to POSIXlt dates format.

6. Now I moved on to N/A(na) values in tripdata columns and birthyear columns.

7. tripduration(with na) was actually end_time - start_time when I compared both. So I replaced it with end_time-start_time.

8. Dealing with na in birth year was an issue, but i imputed them using usertype column. Steps were as follows:
	i) Generated two datasets for subscriber and customer seperatedly.
	ii) Analysed birthyear that most precisely represent these groups using stats and graphs.
	iii) I found that median represent these data clearly as subscribers were generally little older than customer(4 years).
	iv) so I imputed these datasets with respective median values thus getting rid of na values.

9. After step 8 data was cleaned so I merged subscriber_data and customer_data into single 2021_07_20_purified_final.csv.

10. Next new data was sorted by dates start_time and end_time. and checked for duplicates but there were none.

11. Final Cleaned producted was 2021_07_20readyToUse.csv

